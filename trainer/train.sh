python -u -m trainer.train \
    --device cuda:1 \
    --src_language combine \
    --tgt_language en \
    --src_path /data/rrjin/corpus_data/ted_data/src_combine_train_bpe_28000.txt \
    --tgt_path /data/rrjin/corpus_data/ted_data/tgt_en_train_bpe_28000.txt \
    --src_vocab_path /data/rrjin/NMT/data/src_combine_28000.vocab \
    --tgt_vocab_path /data/rrjin/NMT/data/tgt_en_28000.vocab \
    --rnn_type lstm \
    --embedding_size 512 \
    --hidden_size 512 \
    --num_layers 3 \
    --checkpoint /data/rrjin/NMT/data/models/attention_single_gpu_lstm \
    --batch_size 32 \
    --dropout 0.1 \
    --rebuild_vocab False \
    --attention_size 512